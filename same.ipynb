{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f213cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASDF\\anaconda3\\envs\\gnn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813e21e",
   "metadata": {},
   "source": [
    "# Model Construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a84c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    # Applies a linear tranformation to the incoming data\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Add self-loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Multiply with weights\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Calculate the normalization\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4: Propagate the embeddings to the next layer\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x,\n",
    "                              norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7d7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super(Net, self).__init__()\n",
    "        # two convolution layers of GCN\n",
    "        # first represnt the input and the second represnt the output layer\n",
    "        # dataset.num_node_features== number of input\n",
    "        # 16 hidden layers\n",
    "        # dataset.num_classes==outputclass\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "    # represent the weights updates\n",
    "    # weights in output\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "#         print(x)\n",
    "#         print(edge_index)\n",
    "        x = self.conv1(x, edge_index)\n",
    "#         print('first convo X:',x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         print('sec convo X:',x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2421ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_dataset(dataset):\n",
    "#     edges_raw = dataset.data.edge_index.numpy()\n",
    "#     edges = [(x, y) for x, y in zip(edges_raw[0, :], edges_raw[1, :])]\n",
    "#     labels = dataset.data.y.numpy()\n",
    "\n",
    "#     G = nx.Graph()\n",
    "#     G.add_nodes_from(list(range(np.max(edges_raw))))\n",
    "#     G.add_edges_from(edges)\n",
    "#     plt.subplot(111)\n",
    "#     options = {\n",
    "#                 'node_size': 30,\n",
    "#                 'width': 0.2,\n",
    "#     }\n",
    "#     nx.draw(G, with_labels=False, node_color=labels.tolist(), cmap=plt.cm.tab10, font_weight='bold', **options)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "964f7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data, train=True):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    pred = model(data).max(dim=1)[1]\n",
    "\n",
    "    if train:\n",
    "        correct += pred[data.train_mask].eq(data.y[data.train_mask]).sum().item()\n",
    "        return correct / (len(data.y[data.train_mask]))\n",
    "    else:\n",
    "        correct += pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "        return correct / (len(data.y[data.test_mask]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0688fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, plot=False):\n",
    "    train_accuracies, test_accuracies = list(), list()\n",
    "    for epoch in range(100):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc = test(data)\n",
    "            test_acc = test(data, train=False)\n",
    "\n",
    "            train_accuracies.append(train_acc)\n",
    "            test_accuracies.append(test_acc)\n",
    "            print('Epoch: {:03d}, Loss: {:.5f}, Train Acc: {:.5f}, Test Acc: {:.5f}'.\n",
    "                  format(epoch, loss, train_acc, test_acc))\n",
    "\n",
    "    # torch.save(model.state_dict(), 'new_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b854b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if plot:\n",
    "#     plt.plot(train_accuracies, label=\"Train accuracy\")\n",
    "#     plt.plot(test_accuracies, label=\"Validation accuracy\")\n",
    "#     plt.xlabel(\"# Epoch\")\n",
    "#     plt.ylabel(\"Accuracy\")\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa6fe0",
   "metadata": {},
   "source": [
    "# Dataset loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1d5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='cora_dataset', name='Cora')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad50cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cae40f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe9e9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713d1f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155e1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e060a7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37becb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6b01845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "number of graph: 1\n",
      "number of classes: 7\n",
      "number of node features: 1433\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(\"number of graph:\" ,len(dataset))\n",
    "print(\"number of classes:\", dataset.num_classes)\n",
    "print(\"number of node features:\", dataset.num_node_features)\n",
    "# print(\"number of edge features:\\t\",dataset.num_edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d8a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shape:\t torch.Size([2, 10556])\n",
      "edge_index= tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])\n",
      "\n",
      "\n",
      "train_mask shape:\t torch.Size([2708])\n",
      "train_mask= tensor([ True,  True,  True,  ..., False, False, False])\n",
      "\n",
      "\n",
      "x shape:\t torch.Size([2708, 1433])\n",
      "Shape of x= tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "\n",
      "\n",
      "y shape:\t torch.Size([2708])\n",
      "y tensor([3, 4, 4,  ..., 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_index shape:\\t\", dataset.data.edge_index.shape)\n",
    "print(\"edge_index=\",dataset.data.edge_index)\n",
    "print('\\n')\n",
    "print(\"train_mask shape:\\t\", dataset.data.train_mask.shape)\n",
    "print(\"train_mask=\",dataset.data.train_mask)\n",
    "print('\\n')\n",
    "print(\"x shape:\\t\", dataset.data.x.shape)\n",
    "print(\"Shape of x=\",dataset.data.x)\n",
    "print('\\n')\n",
    "print(\"y shape:\\t\", dataset.data.y.shape)\n",
    "print('y',dataset.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a779e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal data view:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mdata\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Total data view:\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee4e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9103f9b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m Net(dataset)\u001b[38;5;241m.\u001b[39mto(\u001b[43mdevice\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model = Net(dataset).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af318049",
   "metadata": {},
   "source": [
    "# Train model function call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460617db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f91e1",
   "metadata": {},
   "source": [
    "# Prediction on direct model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model(dataset[0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ecdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('prediction_by_model:',[np.argmax(i) for i in y_pred.tolist()])\n",
    "print('actual y values____:',dataset[0].y.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e090d5",
   "metadata": {},
   "source": [
    "# Model saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving complete model\n",
    "torch.save(model, 'Updated_GNN_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load('GNN_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fbb96",
   "metadata": {},
   "source": [
    "# Prediction on loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model(dataset[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db158552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('prediction_by_model:',[np.argmax(i) for i in y_pred.tolist()])\n",
    "print('actual y values____:',dataset[0].y.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a5818",
   "metadata": {},
   "source": [
    "# Code End here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(dataset.data.x[1],dataset.data.edge_index,dataset.data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbfa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"number of graph:\" ,len(dataset))\n",
    "    print(\"number of classes:\", dataset.num_classes)\n",
    "    print(\"number of node features:\", dataset.num_node_features)\n",
    "    # print(\"number of edges:\",dataset.num_edge_features_features)\n",
    "\n",
    "    print(\"edge_index:\\t\\t\", dataset.data.edge_index.shape)\n",
    "    print(dataset.data.edge_index)\n",
    "    print(\"\\n\")\n",
    "    print(\"train_mask:\\t\\t\", dataset.data.train_mask.shape)\n",
    "    print(dataset.data.train_mask)\n",
    "    print(\"\\n\")\n",
    "    print(\"x:\\t\\t\", dataset.data.x.shape)\n",
    "    print(dataset.data.x)\n",
    "    print(\"\\n\")\n",
    "    print(\"y:\\t\\t\", dataset.data.y.shape)\n",
    "    print(dataset.data.y)\n",
    "\n",
    "    # print('x values',dataset[0].x)\n",
    "    sg_x=dataset[0].x.tolist()[1]\n",
    "    # print(\"signal record\",dataset[0].x.tolist()[1])\n",
    "    sg_ed = dataset[0].edge_index.tolist()[1]\n",
    "    # print(sg_ed )\n",
    "    # print('y values',dataset[0].y)\n",
    "    # print('complete values',dataset[0])\n",
    "\n",
    "    # plot_dataset(dataset)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Net(dataset).to(device)\n",
    "    data = dataset[0].to(device)\n",
    "    print(\"data check\",data)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    # train(data, plot=True)\n",
    "\n",
    "    # saving and load with other approch\n",
    "    # torch.save(model.state_dict(), 'dic_state_save_model.pt')\n",
    "    # the_model = model()\n",
    "\n",
    "    # the_model.load_state_dict(torch.load(PATH))\n",
    "    # ___________\n",
    "    # saving complete model\n",
    "    torch.save(model, 'GNN_model_weights.pth')\n",
    "    # load model\n",
    "    model = torch.load('GNN_model_weights.pth')\n",
    "    # print(model.eval())\n",
    "\n",
    "    # prediction of all datset\n",
    "    print(\"test=\",dataset[0])\n",
    "    print(\"complete dataset: =\", dataset)\n",
    "    \n",
    "    y_pred=model(dataset[0])\n",
    "    # print(y_pred)\n",
    "    print('prediction_by_model:',[np.argmax(i) for i in y_pred.tolist()])\n",
    "    print('actual y values____:',dataset[0].y.tolist())\n",
    "    print('data_x',data.x)\n",
    "    print('data_edges',data.edge_index)\n",
    "    # test_data(x=data.x,edge_index=data.edge_index)\n",
    "    print('zero......',data.x[0])\n",
    "    print('last....',data.x[2707])\n",
    "    # res=model(data.x[])\n",
    "    # print(res)\n",
    "\n",
    "\n",
    "\n",
    "    di={\n",
    "        'predicted':[np.argmax(i) for i in y_pred.tolist()],\n",
    "        'actual':dataset[0].y,\n",
    "    }\n",
    "\n",
    "    #\n",
    "    # print(model(di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "print(dataset)\n",
    "print(\"number of graph:\" ,len(dataset))\n",
    "print(\"number of classes:\", dataset.num_classes)\n",
    "print(\"number of node features:\", dataset.num_node_features)\n",
    "# print(\"number of edges:\",dataset.num_edge_features_features)\n",
    "\n",
    "#     print(\"edge_index:\\t\\t\", dataset.data.edge_index.shape)\n",
    "#     print(dataset.data.edge_index)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"train_mask:\\t\\t\", dataset.data.train_mask.shape)\n",
    "#     print(dataset.data.train_mask)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"x:\\t\\t\", dataset.data.x.shape)\n",
    "#     print(dataset.data.x)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"y:\\t\\t\", dataset.data.y.shape)\n",
    "#     print(dataset.data.y)\n",
    "\n",
    "    # print('x values',dataset[0].x)\n",
    "sg_x=dataset[0].x.tolist()[1]\n",
    "    # print(\"signal record\",dataset[0].x.tolist()[1])\n",
    "sg_ed = dataset[0].edge_index.tolist()[1]\n",
    "    # print(sg_ed )\n",
    "    # print('y values',dataset[0].y)\n",
    "    # print('complete values',dataset[0])\n",
    "\n",
    "    # plot_dataset(dataset)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(dataset).to(device)\n",
    "data = dataset[0].to(device)\n",
    "print(\"data check\",data)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    # train(data, plot=True)\n",
    "\n",
    "    # saving and load with other approch\n",
    "    # torch.save(model.state_dict(), 'dic_state_save_model.pt')\n",
    "    # the_model = model()\n",
    "\n",
    "    # the_model.load_state_dict(torch.load(PATH))\n",
    "    # ___________\n",
    "    # saving complete model\n",
    "torch.save(model, 'GNN_model_weights.pth')\n",
    "    # load model\n",
    "model = torch.load('GNN_model_weights.pth')\n",
    "    # print(model.eval())\n",
    "\n",
    "    # prediction of all datset\n",
    "print(\"test=\",dataset[0])\n",
    "print(\"complete dataset: =\", dataset)\n",
    "    \n",
    "y_pred=model(dataset[0])\n",
    "    # print(y_pred)\n",
    "# print('prediction_by_model:',[np.argmax(i) for i in y_pred.tolist()])\n",
    "# print('actual y values____:',dataset[0].y.tolist())\n",
    "# print('data_x',data.x)\n",
    "#     print('data_edges',data.edge_index)\n",
    "#     # test_data(x=data.x,edge_index=data.edge_index)\n",
    "#     print('zero......',data.x[0])\n",
    "#     print('last....',data.x[2707])\n",
    "#     # res=model(data.x[])\n",
    "    # print(res)\n",
    "\n",
    "\n",
    "\n",
    "#     di={\n",
    "#         'predicted':[np.argmax(i) for i in y_pred.tolist()],\n",
    "#         'actual':dataset[0].y,\n",
    "#     }\n",
    "\n",
    "    #\n",
    "    # print(model(di))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.x.reshape(1,1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=model(data.x)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec196ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('zero......:',data.x[0])\n",
    "# print('last......',data.x[2700])\n",
    "print('y.........:',data.y[0])\n",
    "print('mask_train zero:',data.train_mask[0])\n",
    "print('val_mask zero:',data.val_mask[0])\n",
    "print('test_mask zero:',data.test_mask[0])\n",
    "print('total_dataset',dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.x[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3da919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=model(data.x[0],data.edge_index,data.y[0])\n",
    "# y_pred=model(data.x[0],data.edge_index,data.val_mask[0],data.test_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "    print(dataset)\n",
    "    print(\"number of graph:\" ,len(dataset))\n",
    "    print(\"number of classes:\", dataset.num_classes)\n",
    "    print(\"number of node features:\", dataset.num_node_features)\n",
    "    # print(\"number of edges:\",dataset.num_edge_features_features)\n",
    "\n",
    "    print(\"edge_index:\\t\\t\", dataset.data.edge_index.shape)\n",
    "    print(dataset.data.edge_index)\n",
    "    print(\"\\n\")\n",
    "    print(\"train_mask:\\t\\t\", dataset.data.train_mask.shape)\n",
    "    print(dataset.data.train_mask)\n",
    "    print(\"\\n\")\n",
    "    print(\"x:\\t\\t\", dataset.data.x.shape)\n",
    "    print(dataset.data.x)\n",
    "    print(\"\\n\")\n",
    "    print(\"y:\\t\\t\", dataset.data.y.shape)\n",
    "    print(dataset.data.y)\n",
    "\n",
    "    # print('x values',dataset[0].x)\n",
    "    sg_x=dataset[0].x.tolist()[1]\n",
    "    # print(\"signal record\",dataset[0].x.tolist()[1])\n",
    "    sg_ed = dataset[0].edge_index.tolist()[1]\n",
    "    # print(sg_ed )\n",
    "    # print('y values',dataset[0].y)\n",
    "    # print('complete values',dataset[0])\n",
    "\n",
    "    # plot_dataset(dataset)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Net(dataset).to(device)\n",
    "    data = dataset[0].to(device)\n",
    "    print(\"data check\",data)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    # train(data, plot=True)\n",
    "\n",
    "    # saving and load with other approch\n",
    "    # torch.save(model.state_dict(), 'dic_state_save_model.pt')\n",
    "    # the_model = model()\n",
    "\n",
    "    # the_model.load_state_dict(torch.load(PATH))\n",
    "    # ___________\n",
    "    # saving complete model\n",
    "    torch.save(model, 'GNN_model_weights.pth')\n",
    "    # load model\n",
    "    model = torch.load('GNN_model_weights.pth')\n",
    "    # print(model.eval())\n",
    "\n",
    "    # prediction of all datset\n",
    "    print(\"test=\",dataset[0])\n",
    "    print(\"complete dataset: =\", dataset)\n",
    "    \n",
    "    y_pred=model(dataset[0])\n",
    "    # print(y_pred)\n",
    "    print('prediction_by_model:',[np.argmax(i) for i in y_pred.tolist()])\n",
    "    print('actual y values____:',dataset[0].y.tolist())\n",
    "    print('data_x',data.x)\n",
    "    print('data_edges',data.edge_index)\n",
    "    # test_data(x=data.x,edge_index=data.edge_index)\n",
    "    print('zero......',data.x[0])\n",
    "    print('last....',data.x[2707])\n",
    "    # res=model(data.x[])\n",
    "    # print(res)\n",
    "\n",
    "\n",
    "\n",
    "    di={\n",
    "        'predicted':[np.argmax(i) for i in y_pred.tolist()],\n",
    "        'actual':dataset[0].y,\n",
    "    }\n",
    "\n",
    "    #\n",
    "    # print(model(di))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
