{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f76e6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1f25731",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e3d6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12896/2411067426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# a data object to a list of tuples (train_data, val_data, test_data), with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# each element representing the corresponding split.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '', 'data', 'Planetoid')\n",
    "dataset = Planetoid(root='cora_dataset_n', name='Cora')\n",
    "data=dataset[0]\n",
    "print('Test data:',dataset[0])\n",
    "# dataset = Planetoid(path, name='Cora',transform=transform )\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "405623e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82631f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4bafefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bb4ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96c02549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Val: 0.6669, Test: 0.6988\n",
      "Epoch: 002, Loss: 0.6825, Val: 0.6648, Test: 0.6922\n",
      "Epoch: 003, Loss: 0.7094, Val: 0.6702, Test: 0.6999\n",
      "Epoch: 004, Loss: 0.6774, Val: 0.6938, Test: 0.7253\n",
      "Epoch: 005, Loss: 0.6851, Val: 0.7223, Test: 0.7549\n",
      "Epoch: 006, Loss: 0.6884, Val: 0.7192, Test: 0.7593\n",
      "Epoch: 007, Loss: 0.6890, Val: 0.6904, Test: 0.7367\n",
      "Epoch: 008, Loss: 0.6877, Val: 0.6699, Test: 0.7167\n",
      "Epoch: 009, Loss: 0.6845, Val: 0.6613, Test: 0.7043\n",
      "Epoch: 010, Loss: 0.6789, Val: 0.6586, Test: 0.6962\n",
      "Epoch: 011, Loss: 0.6755, Val: 0.6622, Test: 0.6918\n",
      "Epoch: 012, Loss: 0.6778, Val: 0.6681, Test: 0.6902\n",
      "Epoch: 013, Loss: 0.6732, Val: 0.6756, Test: 0.6888\n",
      "Epoch: 014, Loss: 0.6676, Val: 0.6831, Test: 0.6908\n",
      "Epoch: 015, Loss: 0.6642, Val: 0.6918, Test: 0.6954\n",
      "Epoch: 016, Loss: 0.6602, Val: 0.6975, Test: 0.6954\n",
      "Epoch: 017, Loss: 0.6548, Val: 0.6986, Test: 0.6921\n",
      "Epoch: 018, Loss: 0.6459, Val: 0.7006, Test: 0.6912\n",
      "Epoch: 019, Loss: 0.6417, Val: 0.7117, Test: 0.7037\n",
      "Epoch: 020, Loss: 0.6338, Val: 0.7443, Test: 0.7428\n",
      "Epoch: 021, Loss: 0.6250, Val: 0.7967, Test: 0.7971\n",
      "Epoch: 022, Loss: 0.6143, Val: 0.8204, Test: 0.8257\n",
      "Epoch: 023, Loss: 0.6033, Val: 0.8239, Test: 0.8296\n",
      "Epoch: 024, Loss: 0.5881, Val: 0.8248, Test: 0.8275\n",
      "Epoch: 025, Loss: 0.5741, Val: 0.8369, Test: 0.8399\n",
      "Epoch: 026, Loss: 0.5561, Val: 0.8484, Test: 0.8487\n",
      "Epoch: 027, Loss: 0.5355, Val: 0.8527, Test: 0.8470\n",
      "Epoch: 028, Loss: 0.5249, Val: 0.8556, Test: 0.8468\n",
      "Epoch: 029, Loss: 0.5121, Val: 0.8578, Test: 0.8466\n",
      "Epoch: 030, Loss: 0.4982, Val: 0.8601, Test: 0.8489\n",
      "Epoch: 031, Loss: 0.5247, Val: 0.8639, Test: 0.8506\n",
      "Epoch: 032, Loss: 0.5262, Val: 0.8668, Test: 0.8526\n",
      "Epoch: 033, Loss: 0.5101, Val: 0.8669, Test: 0.8578\n",
      "Epoch: 034, Loss: 0.5030, Val: 0.8677, Test: 0.8602\n",
      "Epoch: 035, Loss: 0.5089, Val: 0.8720, Test: 0.8600\n",
      "Epoch: 036, Loss: 0.4898, Val: 0.8753, Test: 0.8631\n",
      "Epoch: 037, Loss: 0.4866, Val: 0.8769, Test: 0.8684\n",
      "Epoch: 038, Loss: 0.4865, Val: 0.8778, Test: 0.8700\n",
      "Epoch: 039, Loss: 0.4820, Val: 0.8852, Test: 0.8744\n",
      "Epoch: 040, Loss: 0.4816, Val: 0.8910, Test: 0.8778\n",
      "Epoch: 041, Loss: 0.4776, Val: 0.8924, Test: 0.8807\n",
      "Epoch: 042, Loss: 0.4821, Val: 0.8921, Test: 0.8822\n",
      "Epoch: 043, Loss: 0.4726, Val: 0.8924, Test: 0.8826\n",
      "Epoch: 044, Loss: 0.4846, Val: 0.8944, Test: 0.8840\n",
      "Epoch: 045, Loss: 0.4801, Val: 0.8977, Test: 0.8865\n",
      "Epoch: 046, Loss: 0.4723, Val: 0.8995, Test: 0.8882\n",
      "Epoch: 047, Loss: 0.4765, Val: 0.9003, Test: 0.8890\n",
      "Epoch: 048, Loss: 0.4774, Val: 0.9005, Test: 0.8887\n",
      "Epoch: 049, Loss: 0.4732, Val: 0.9011, Test: 0.8896\n",
      "Epoch: 050, Loss: 0.4739, Val: 0.9019, Test: 0.8900\n",
      "Epoch: 051, Loss: 0.4697, Val: 0.9013, Test: 0.8891\n",
      "Epoch: 052, Loss: 0.4725, Val: 0.8993, Test: 0.8872\n",
      "Epoch: 053, Loss: 0.4718, Val: 0.8999, Test: 0.8864\n",
      "Epoch: 054, Loss: 0.4699, Val: 0.9016, Test: 0.8858\n",
      "Epoch: 055, Loss: 0.4704, Val: 0.9021, Test: 0.8860\n",
      "Epoch: 056, Loss: 0.4757, Val: 0.9035, Test: 0.8868\n",
      "Epoch: 057, Loss: 0.4654, Val: 0.9037, Test: 0.8874\n",
      "Epoch: 058, Loss: 0.4648, Val: 0.9045, Test: 0.8883\n",
      "Epoch: 059, Loss: 0.4660, Val: 0.9072, Test: 0.8898\n",
      "Epoch: 060, Loss: 0.4555, Val: 0.9083, Test: 0.8912\n",
      "Epoch: 061, Loss: 0.4638, Val: 0.9105, Test: 0.8929\n",
      "Epoch: 062, Loss: 0.4669, Val: 0.9119, Test: 0.8937\n",
      "Epoch: 063, Loss: 0.4627, Val: 0.9125, Test: 0.8944\n",
      "Epoch: 064, Loss: 0.4595, Val: 0.9142, Test: 0.8959\n",
      "Epoch: 065, Loss: 0.4556, Val: 0.9149, Test: 0.8971\n",
      "Epoch: 066, Loss: 0.4623, Val: 0.9156, Test: 0.8983\n",
      "Epoch: 067, Loss: 0.4536, Val: 0.9181, Test: 0.8989\n",
      "Epoch: 068, Loss: 0.4591, Val: 0.9190, Test: 0.8991\n",
      "Epoch: 069, Loss: 0.4544, Val: 0.9200, Test: 0.8996\n",
      "Epoch: 070, Loss: 0.4555, Val: 0.9214, Test: 0.9011\n",
      "Epoch: 071, Loss: 0.4578, Val: 0.9221, Test: 0.9021\n",
      "Epoch: 072, Loss: 0.4531, Val: 0.9229, Test: 0.9023\n",
      "Epoch: 073, Loss: 0.4483, Val: 0.9242, Test: 0.9030\n",
      "Epoch: 074, Loss: 0.4536, Val: 0.9256, Test: 0.9036\n",
      "Epoch: 075, Loss: 0.4556, Val: 0.9264, Test: 0.9047\n",
      "Epoch: 076, Loss: 0.4507, Val: 0.9270, Test: 0.9048\n",
      "Epoch: 077, Loss: 0.4484, Val: 0.9266, Test: 0.9052\n",
      "Epoch: 078, Loss: 0.4549, Val: 0.9275, Test: 0.9056\n",
      "Epoch: 079, Loss: 0.4442, Val: 0.9285, Test: 0.9057\n",
      "Epoch: 080, Loss: 0.4519, Val: 0.9282, Test: 0.9065\n",
      "Epoch: 081, Loss: 0.4455, Val: 0.9280, Test: 0.9072\n",
      "Epoch: 082, Loss: 0.4505, Val: 0.9286, Test: 0.9071\n",
      "Epoch: 083, Loss: 0.4418, Val: 0.9302, Test: 0.9070\n",
      "Epoch: 084, Loss: 0.4419, Val: 0.9303, Test: 0.9083\n",
      "Epoch: 085, Loss: 0.4458, Val: 0.9299, Test: 0.9087\n",
      "Epoch: 086, Loss: 0.4387, Val: 0.9290, Test: 0.9083\n",
      "Epoch: 087, Loss: 0.4442, Val: 0.9295, Test: 0.9085\n",
      "Epoch: 088, Loss: 0.4437, Val: 0.9312, Test: 0.9092\n",
      "Epoch: 089, Loss: 0.4481, Val: 0.9315, Test: 0.9092\n",
      "Epoch: 090, Loss: 0.4467, Val: 0.9301, Test: 0.9102\n",
      "Epoch: 091, Loss: 0.4490, Val: 0.9288, Test: 0.9104\n",
      "Epoch: 092, Loss: 0.4389, Val: 0.9289, Test: 0.9100\n",
      "Epoch: 093, Loss: 0.4374, Val: 0.9307, Test: 0.9103\n",
      "Epoch: 094, Loss: 0.4386, Val: 0.9312, Test: 0.9103\n",
      "Epoch: 095, Loss: 0.4479, Val: 0.9300, Test: 0.9109\n",
      "Epoch: 096, Loss: 0.4458, Val: 0.9288, Test: 0.9115\n",
      "Epoch: 097, Loss: 0.4371, Val: 0.9294, Test: 0.9123\n",
      "Epoch: 098, Loss: 0.4440, Val: 0.9300, Test: 0.9116\n",
      "Epoch: 099, Loss: 0.4467, Val: 0.9315, Test: 0.9126\n",
      "Epoch: 100, Loss: 0.4391, Val: 0.9298, Test: 0.9124\n",
      "Final Test: 0.9124\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "239329b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[1358,  505,    6,  ..., 2274, 2472, 1681],\n",
       "         [1731, 1448, 1042,  ..., 1370,  192,  459]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.x, train_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12f08d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving complete model\n",
    "torch.save(model, 'Link_prediction_GNN_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14b9cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load('Link_prediction_GNN_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6eee88e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12896/2096484349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\graph_neural_network\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graph_neural_network\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "886096a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10152bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "366b0969",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12896/3600659566.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graph_neural_network\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\graph_neural_network\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \"\"\"\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred=model(data[1])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d3e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
