{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca76a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tubaid\\Anaconda3\\envs\\GNN\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18100\\3882189626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Reddit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReddit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "\n",
    "# Already send node features/labels to GPU for faster access during sampling:\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "\n",
    "kwargs = {'batch_size': 1024, 'num_workers': 6, 'persistent_workers': True}\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "\n",
    "subgraph_loader = NeighborLoader(copy.copy(data), input_nodes=None,\n",
    "                                 num_neighbors=[-1], shuffle=False, **kwargs)\n",
    "\n",
    "# No need to maintain these features during evaluation:\n",
    "del subgraph_loader.data.x, subgraph_loader.data.y\n",
    "# Add global node index information.\n",
    "subgraph_loader.data.num_nodes = data.num_nodes\n",
    "subgraph_loader.data.n_id = torch.arange(data.num_nodes)\n",
    "\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, x_all, subgraph_loader):\n",
    "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))\n",
    "        pbar.set_description('Evaluating')\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch:\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            xs = []\n",
    "            for batch in subgraph_loader:\n",
    "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
    "                x = conv(x, batch.edge_index.to(device))\n",
    "                if i < len(self.convs) - 1:\n",
    "                    x = x.relu_()\n",
    "                xs.append(x[:batch.batch_size].cpu())\n",
    "                pbar.update(batch.batch_size)\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "        pbar.close()\n",
    "        return x_all\n",
    "\n",
    "\n",
    "model = SAGE(dataset.num_features, 256, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.batch_size\n",
    "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples += batch.batch_size\n",
    "        pbar.update(batch.batch_size)\n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    y_hat = model.inference(data.x, subgraph_loader).argmax(dim=-1)\n",
    "    y = data.y.to(y_hat.device)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((y_hat[mask] == y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "          f'Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ca229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
